---
layout: post
title: '공적마스크 더미 API 운영기'
author: junsu.lee
date: 2020-07-27 19:00
tags: [dev, civic-hacking]
---

## 이시국 유럽 여행객

2020년 2월 초, 이탈리아와 스위스로의 여행을 다녀왔습니다. 그 당시에는 유럽 지역의 코로나19 확산세가 심각하지 않았고, 오히려 **한국에서 도망쳐야(?) 한다**는 이야기가 나올 정도였습니다. 

출국 전에 2015년의 **메르스 사태**가 떠올랐습니다. 사실, 그 당시 운영되었던 **메르스맵**이 코로나19 상황에서도 다시 떠오르지 않을까 하는 생각을 하고 있었습니다. 실제로 얼마 지나지 않아서 **코로나맵**이 운영되기 시작했고, 인천공항으로 향했습니다.

그 후로 다양한 확진자 동선 정보 안내 서비스 등이 출시된 것을 이탈리아 여행을 하며 꾸준히 확인할 수 있었습니다. 하지만, 과거의 경향과는 무언가 미묘한 다른 출발 양상이 느껴졌습니다. 언제나 슬픈 예감은 틀리지 않았습니다. 귀국 당일, 특정 종교의 집단 감염 사태가 발생했고, 상황이 매우 심각해질 그것으로 예상하였습니다.




## 코로나19 공익데이터 공동대응

산재한 코로나19 시기의 안전 관련 정보를 찾아다니기 어려운 점이 아쉬워, **코로나 관련 정보 서비스** 개발에 뛰어들었습니다. 이를 위해서 대략 15개 이상의 공공데이터를 수집했으며, 기타 비정형 데이터의 출처도 모두 정리하였습니다. 정보를 수집하고 정리하는 활동을 하며, 저의 이런 행적을 알아보신 분께서 연락을 주셨습니다.

> OOO 개발자님을 비롯해 애써주시는 분들과 좀 더 수월하게 코로나19 데이터에 관해 협업하는 방법으로, 내용과 형식을 맞추고 Open API로 제공하는 등 여러 방법이 있지 않을까를 고민합니다. 코로나19 공공데이터에 대해 공동 대응하기를 희망합니다. 그래서 데이터 소스와 작업방식, 협업의향에 대해 여쭈어보려 연락드립니다.

정부에서 공개하고 있는 코로나19 관련 정보가 일관된 형태로 제공되지 않고 있어, 기계적으로 가공 및 활용하기 불편하다는 점을 느끼고 있었기 때문에 '코로나19 공익데이터 공동대응'에 함께 하게 되었습니다. 2월 24일부터 28일 사이에 공공데이터 개방 제안서를 작성했고, 3월 2일에 [최종 제안서](https://www.gwanghwamoon1st.go.kr/front/propseTalk/propseTalkViewPage.do?propse_id=7a6f646cb53c4ac39ff694522ee0c04e)를 광화문 1번가 혁신제안톡에 올렸습니다.




## 정보화진흥원의 즉시 응답

정보화진흥원은 혁신제안톡이 등록된 바로 다음 날, `선별진료소`와 `국민 안심 병원` 정보를 정형화된 엑셀 파일 형태로 변환하여 공공데이터포털에 올렸습니다. 이후, 제안서 내의 방역물품 현황을 확장하여 공적마스크 제도와 연계 추진하겠다는 입장을 밝혀 왔습니다. 그 후로 3월 6일쯤, HWP 형태의 공적마스크 재고 정보 API 명세서를 전달받게 됩니다.




## 공적마스크 더미 API 개발 착수

처음 전달받았던 명세서는 필드명과 일부 형식만 존재한 단순한 형태였습니다. 하지만, 개발자라면 모두 알고 있듯이 샘플 데이터와 테스트할 수 있는 API Endpoint의 존재 차이가 개발 속도를 좌우한다는 것을 아실 겁니다. 그래서 불필요한 샘플 데이터를 직접 생성하지 않아도 되고, 실 서비스에 이용될 코드와 크게 달라지지 않는 선에서 이용할 수 있도록 하고자 했습니다.

명세서 초안을 전달받은 당일 저녁부터 샘플 API 개발하기를 시작했습니다. 항상 익숙하게 사용해온 라라벨과 MySQL 기반으로 3월 7일 공개를 목표로 빠르게 달려가기 시작했습니다. 사실 다시 와서 생각 해보면 정말 말도 안 되는 오버스펙의 프레임워크를 사용했던 것 같기도 하고, API를 표적으로 한 Laravel Lumen이라는 더 나은 선택지도 있었기 때문입니다.




## 망한 최적화 사례

지도에 마커를 찍는 경우, 사용자의 지도 이동 이벤트 발생 때마다 원천 데이터를 호출할 수도 있다는 사실을 간과했습니다. 최적화를 최소한 발을 이용해서라도 하지 않았던 코드였기에, 요청 당 처리 시간이 1초 이상으로 넘어가기 시작했습니다.

최초 개발 당시에는 그리 많은 트래픽이 몰릴 것이라고 예상하지 못했기 때문에, 무식한(?)방법을 이용하여 가상 재고 정보를 생성했습니다. 사각형 범위로 약국을 SELECT한 후, foreach를 돌리며 일일히 rand 함수를 돌리는 방식이었습니다. 과도한 데이터베이스 호출과 연산을 일으키는 구조였던 것입니다.



##  듬직한 일꾼 Cron Job 영입

이러한 상황을 보며, 한 가지 묘수를 떠올렸습니다. 바로, **"재고 정보를 디비에 미리 꽂아놓자!"**라는 해괴한 발상말이죠. 그래도 성능 지표상으로는 아주(!) 미묘한 차이가 보이긴 했습니다. 단지 그것이 실제 체감 될만큼의 영향을 가지지는 않았다는 것이 문제였습니다.

Laravel Artisan 커맨드로 작성된 `UpdateStockInformation`은 5분 주기로, **무려 전체 약국 정보를 불러와서** foreach를 이용해 한 row씩 UPDATE를 수행하였습니다. ~~차라리 이렇게 안 하는 방법이 나았을지도 몰라요.~~ 

다행히 교훈은 얻었습니다.

1. Eloquent 모델의 Mass Assignment를 활용 하지 그랬냐!!
2. 원천 데이터와 실 서비스 데이터 DB를 분리하는 편이 낫다.
3. 크론을 도입하려고 한 것은 좋은 시도였다.



## 다시, 새롭게 만나는 Redis

